<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Heading paragraphs</title>
</head>
<body>
    <h1>RITIK</h1>
    <h2>RITIK</h2>
    <h3>RITIK</h3>
    <h4>RITIK</h4>
    <h5>RITIK</h5>
<p>              Our application has two buttons in the main activity page, first one is Text button and the second one is Speech. The Text button connects the main activity with another activity which has two options the first one is capture image button which is used to take image from camera or select from the gallery and after capturing or selecting the image containing the text, we can extract the text captured by using the other button “Detect Text” which is just below the “Capture Image” button. After clicking on the Detect text button it uses Firebase ML Vision API to display the text on the text view. In the main activity the second button <strong>Speech</strong> connects the main activity to another activity which “Start Reading” button which opens the surface view and extracts the text and displays the extracted text on the text view and detects the text language and convert the text into speech by using google vision API. The Text detected can also be translated into regional Indian languages like Hindi, Bengali, Kannada, Urdu, Marathi using language select option and the translated text can be displayed on text view below the choose language option by using google ML kit translate and ML kit language API’s and If someone wants to give any feedback or faces any bug, they can report to us by going into the main activity and there is bug report feature </p>

<p>first</p>
<p>second</p>
<p>Third</p>
<p>Fourth</p>
</body>
</html>